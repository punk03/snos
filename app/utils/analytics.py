"""
–ú–æ–¥—É–ª—å –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –∏ —Å–±–æ—Ä–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
"""
import logging
import json
import io
import base64
from typing import Dict, Any, List, Optional, Union, Tuple
from datetime import datetime, timedelta
import csv

import config
from app.database.db import db

logger = logging.getLogger(__name__)

class AnalyticsManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∞–Ω–∞–ª–∏—Ç–∏–∫–æ–π –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π"""
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏"""
        logger.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω AnalyticsManager")
    
    def get_user_report_stats(self, user_id: int, days: int = 30) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö –∂–∞–ª–æ–± –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        
        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            days: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            Dict[str, Any]: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∂–∞–ª–æ–±
        """
        try:
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –ë–î
            conn = db.pool.get_connection()
            if not conn:
                return {"error": "database_connection_error"}
                
            cursor = conn.cursor()
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–µ—Ä–∏–æ–¥
            end_date = datetime.now()
            start_date = end_date - timedelta(days=days)
            start_date_str = start_date.strftime("%Y-%m-%d %H:%M:%S")
            
            # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–ø–µ—Ä–∞—Ü–∏–π –æ—Ç–ø—Ä–∞–≤–∫–∏ –∂–∞–ª–æ–±
            cursor.execute(
                """
                SELECT COUNT(*) as count FROM operations
                WHERE user_id = ? AND operation_type = 'report'
                AND created_at >= ?
                """,
                (user_id, start_date_str)
            )
            total_reports = cursor.fetchone()['count']
            
            # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º –∂–∞–ª–æ–±
            cursor.execute(
                """
                SELECT result FROM operations
                WHERE user_id = ? AND operation_type = 'report_result'
                AND created_at >= ?
                """,
                (user_id, start_date_str)
            )
            
            result_rows = cursor.fetchall()
            
            # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –∫–∞–Ω–∞–ª–∞–º
            cursor.execute(
                """
                SELECT target, COUNT(*) as count FROM operations
                WHERE user_id = ? AND operation_type = 'report'
                AND created_at >= ?
                GROUP BY target
                ORDER BY count DESC
                LIMIT ?
                """,
                (user_id, start_date_str, config.UI_SETTINGS.get("charts", {}).get("max_channels", 10))
            )
            
            channel_stats = []
            for row in cursor.fetchall():
                channel_stats.append({
                    "target": row['target'],
                    "count": row['count']
                })
            
            # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –ø—Ä–∏—á–∏–Ω–∞–º –∂–∞–ª–æ–±
            cursor.execute(
                """
                SELECT params, COUNT(*) as count FROM operations
                WHERE user_id = ? AND operation_type = 'report'
                AND created_at >= ?
                GROUP BY params
                ORDER BY count DESC
                """,
                (user_id, start_date_str)
            )
            
            reason_stats = {}
            for row in cursor.fetchall():
                try:
                    params = json.loads(row['params'])
                    reason = params.get('reason', 'other')
                    reason_name = config.REPORT_REASON_NAMES.get(reason, "–î—Ä—É–≥–æ–µ")
                    
                    if reason_name in reason_stats:
                        reason_stats[reason_name] += row['count']
                    else:
                        reason_stats[reason_name] = row['count']
                except:
                    pass
            
            # –ü–æ–ª—É—á–∞–µ–º –¥–∏–Ω–∞–º–∏–∫—É –æ—Ç–ø—Ä–∞–≤–∫–∏ –∂–∞–ª–æ–± –ø–æ –¥–Ω—è–º
            cursor.execute(
                """
                SELECT DATE(created_at) as date, COUNT(*) as count
                FROM operations
                WHERE user_id = ? AND operation_type = 'report'
                AND created_at >= ?
                GROUP BY DATE(created_at)
                ORDER BY date
                """,
                (user_id, start_date_str)
            )
            
            daily_stats = []
            for row in cursor.fetchall():
                daily_stats.append({
                    "date": row['date'],
                    "count": row['count']
                })
            
            db.pool.release_connection(conn)
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∂–∞–ª–æ–±
            valid_reports = 0
            invalid_reports = 0
            flood_reports = 0
            
            for row in result_rows:
                try:
                    result_data = json.loads(row['result'])
                    valid_reports += result_data.get('valid', 0)
                    invalid_reports += result_data.get('invalid', 0)
                    flood_reports += result_data.get('flood', 0)
                except:
                    pass
            
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –æ–±—â—É—é —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
            total_processed = valid_reports + invalid_reports + flood_reports
            effectiveness = (valid_reports / total_processed * 100) if total_processed > 0 else 0
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            return {
                "total_reports": total_reports,
                "valid_reports": valid_reports,
                "invalid_reports": invalid_reports,
                "flood_reports": flood_reports,
                "effectiveness": round(effectiveness, 2),
                "channels": channel_stats,
                "reasons": reason_stats,
                "daily_stats": daily_stats,
                "period_days": days
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∂–∞–ª–æ–± –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {e}")
            return {"error": str(e)}
    
    def get_global_report_stats(self, days: int = 7) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –≥–ª–æ–±–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö –∂–∞–ª–æ–±
        
        Args:
            days: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            Dict[str, Any]: –ì–ª–æ–±–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        """
        try:
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –ë–î
            conn = db.pool.get_connection()
            if not conn:
                return {"error": "database_connection_error"}
                
            cursor = conn.cursor()
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–µ—Ä–∏–æ–¥
            end_date = datetime.now()
            start_date = end_date - timedelta(days=days)
            start_date_str = start_date.strftime("%Y-%m-%d %H:%M:%S")
            
            # –ü–æ–ª—É—á–∞–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–ø–µ—Ä–∞—Ü–∏–π –æ—Ç–ø—Ä–∞–≤–∫–∏ –∂–∞–ª–æ–±
            cursor.execute(
                """
                SELECT COUNT(*) as count FROM operations
                WHERE operation_type = 'report'
                AND created_at >= ?
                """,
                (start_date_str,)
            )
            total_reports = cursor.fetchone()['count']
            
            # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
            cursor.execute(
                """
                SELECT COUNT(DISTINCT user_id) as count FROM operations
                WHERE operation_type = 'report'
                AND created_at >= ?
                """,
                (start_date_str,)
            )
            unique_users = cursor.fetchone()['count']
            
            # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º –∂–∞–ª–æ–±
            cursor.execute(
                """
                SELECT result FROM operations
                WHERE operation_type = 'report_result'
                AND created_at >= ?
                """,
                (start_date_str,)
            )
            
            result_rows = cursor.fetchall()
            
            # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –∫–∞–Ω–∞–ª–∞–º
            cursor.execute(
                """
                SELECT target, COUNT(*) as count FROM operations
                WHERE operation_type = 'report'
                AND created_at >= ?
                GROUP BY target
                ORDER BY count DESC
                LIMIT ?
                """,
                (start_date_str, config.UI_SETTINGS.get("charts", {}).get("max_channels", 10))
            )
            
            channel_stats = []
            for row in cursor.fetchall():
                channel_stats.append({
                    "target": row['target'],
                    "count": row['count']
                })
            
            # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –ø—Ä–∏—á–∏–Ω–∞–º –∂–∞–ª–æ–±
            cursor.execute(
                """
                SELECT params, COUNT(*) as count FROM operations
                WHERE operation_type = 'report'
                AND created_at >= ?
                GROUP BY params
                ORDER BY count DESC
                """,
                (start_date_str,)
            )
            
            reason_stats = {}
            for row in cursor.fetchall():
                try:
                    params = json.loads(row['params'])
                    reason = params.get('reason', 'other')
                    reason_name = config.REPORT_REASON_NAMES.get(reason, "–î—Ä—É–≥–æ–µ")
                    
                    if reason_name in reason_stats:
                        reason_stats[reason_name] += row['count']
                    else:
                        reason_stats[reason_name] = row['count']
                except:
                    pass
            
            # –ü–æ–ª—É—á–∞–µ–º –¥–∏–Ω–∞–º–∏–∫—É –æ—Ç–ø—Ä–∞–≤–∫–∏ –∂–∞–ª–æ–± –ø–æ –¥–Ω—è–º
            cursor.execute(
                """
                SELECT DATE(created_at) as date, COUNT(*) as count
                FROM operations
                WHERE operation_type = 'report'
                AND created_at >= ?
                GROUP BY DATE(created_at)
                ORDER BY date
                """,
                (start_date_str,)
            )
            
            daily_stats = []
            for row in cursor.fetchall():
                daily_stats.append({
                    "date": row['date'],
                    "count": row['count']
                })
            
            db.pool.release_connection(conn)
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∂–∞–ª–æ–±
            valid_reports = 0
            invalid_reports = 0
            flood_reports = 0
            
            for row in result_rows:
                try:
                    result_data = json.loads(row['result'])
                    valid_reports += result_data.get('valid', 0)
                    invalid_reports += result_data.get('invalid', 0)
                    flood_reports += result_data.get('flood', 0)
                except:
                    pass
            
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –æ–±—â—É—é —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
            total_processed = valid_reports + invalid_reports + flood_reports
            effectiveness = (valid_reports / total_processed * 100) if total_processed > 0 else 0
            
            # –°—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è
            avg_reports_per_user = total_reports / unique_users if unique_users > 0 else 0
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            return {
                "total_reports": total_reports,
                "unique_users": unique_users,
                "valid_reports": valid_reports,
                "invalid_reports": invalid_reports,
                "flood_reports": flood_reports,
                "effectiveness": round(effectiveness, 2),
                "avg_reports_per_user": round(avg_reports_per_user, 2),
                "channels": channel_stats,
                "reasons": reason_stats,
                "daily_stats": daily_stats,
                "period_days": days
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –≥–ª–æ–±–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∂–∞–ª–æ–±: {e}")
            return {"error": str(e)}
    
    def generate_user_report(self, user_id: int, days: int = 30, format: str = "text") -> Union[str, bytes]:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –æ –∂–∞–ª–æ–±–∞—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        
        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            days: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            format: –§–æ—Ä–º–∞—Ç –æ—Ç—á–µ—Ç–∞ (text, csv)
            
        Returns:
            Union[str, bytes]: –û—Ç—á–µ—Ç –≤ –∑–∞–ø—Ä–æ—à–µ–Ω–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
        """
        try:
            # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            stats = self.get_user_report_stats(user_id, days)
            
            if "error" in stats:
                return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á–µ—Ç–∞: {stats['error']}"
                
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            user_data = db.get_user(user_id)
            username = user_data.get('username', '') if user_data else ''
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç –≤ –Ω—É–∂–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
            if format == "csv":
                # –°–æ–∑–¥–∞–µ–º CSV –≤ –ø–∞–º—è—Ç–∏
                output = io.StringIO()
                writer = csv.writer(output)
                
                # –ó–∞–≥–æ–ª–æ–≤–æ–∫
                writer.writerow(['–û—Ç—á–µ—Ç –æ –∂–∞–ª–æ–±–∞—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è', f'@{username}', f'ID: {user_id}'])
                writer.writerow(['–ü–µ—Ä–∏–æ–¥:', f'{days} –¥–Ω–µ–π', f'–î–∞—Ç–∞ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}'])
                writer.writerow([])
                
                # –û—Å–Ω–æ–≤–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                writer.writerow(['–û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞'])
                writer.writerow(['–í—Å–µ–≥–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –∂–∞–ª–æ–±:', stats['total_reports']])
                writer.writerow(['–£—Å–ø–µ—à–Ω—ã—Ö –∂–∞–ª–æ–±:', stats['valid_reports']])
                writer.writerow(['–ù–µ—É—Å–ø–µ—à–Ω—ã—Ö –∂–∞–ª–æ–±:', stats['invalid_reports']])
                writer.writerow(['–ñ–∞–ª–æ–± —Å —Ñ–ª—É–¥–æ–º:', stats['flood_reports']])
                writer.writerow(['–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å:', f"{stats['effectiveness']}%"])
                writer.writerow([])
                
                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞–Ω–∞–ª–∞–º
                writer.writerow(['–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞–Ω–∞–ª–∞–º'])
                writer.writerow(['–ö–∞–Ω–∞–ª', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∂–∞–ª–æ–±'])
                
                for channel in stats['channels']:
                    target = channel['target']
                    writer.writerow([target, channel['count']])
                    
                writer.writerow([])
                
                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø—Ä–∏—á–∏–Ω–∞–º
                writer.writerow(['–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø—Ä–∏—á–∏–Ω–∞–º –∂–∞–ª–æ–±'])
                writer.writerow(['–ü—Ä–∏—á–∏–Ω–∞', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ'])
                
                for reason, count in stats['reasons'].items():
                    writer.writerow([reason, count])
                    
                writer.writerow([])
                
                # –î–∏–Ω–∞–º–∏–∫–∞ –ø–æ –¥–Ω—è–º
                writer.writerow(['–î–∏–Ω–∞–º–∏–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –∂–∞–ª–æ–± –ø–æ –¥–Ω—è–º'])
                writer.writerow(['–î–∞—Ç–∞', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ'])
                
                for day in stats['daily_stats']:
                    writer.writerow([day['date'], day['count']])
                
                # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ CSV
                output.seek(0)
                return output.getvalue().encode('utf-8')
                
            else:  # –¢–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç
                # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á–µ—Ç
                report = f"üìä *–û—Ç—á–µ—Ç –æ –∂–∞–ª–æ–±–∞—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è @{username} (ID: {user_id})*\n"
                report += f"üìÜ –ü–µ—Ä–∏–æ–¥: {days} –¥–Ω–µ–π\n"
                report += f"üìÖ –î–∞—Ç–∞ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è: {datetime.now().strftime('%d.%m.%Y %H:%M')}\n\n"
                
                report += "üìà *–û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:*\n"
                report += f"üì® –í—Å–µ–≥–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –∂–∞–ª–æ–±: {stats['total_reports']}\n"
                report += f"‚úÖ –£—Å–ø–µ—à–Ω—ã—Ö –∂–∞–ª–æ–±: {stats['valid_reports']}\n"
                report += f"‚ùå –ù–µ—É—Å–ø–µ—à–Ω—ã—Ö –∂–∞–ª–æ–±: {stats['invalid_reports']}\n"
                report += f"‚ö†Ô∏è –ñ–∞–ª–æ–± —Å —Ñ–ª—É–¥–æ–º: {stats['flood_reports']}\n"
                report += f"üéØ –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å: {stats['effectiveness']}%\n\n"
                
                report += "üîù *–¢–æ–ø –∫–∞–Ω–∞–ª–æ–≤:*\n"
                for i, channel in enumerate(stats['channels'][:5], 1):
                    target = channel['target']
                    report += f"{i}. {target} - {channel['count']} –∂–∞–ª–æ–±\n"
                    
                report += "\nüìã *–ü—Ä–∏—á–∏–Ω—ã –∂–∞–ª–æ–±:*\n"
                for reason, count in stats['reasons'].items():
                    report += f"‚Ä¢ {reason}: {count}\n"
                
                return report
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á–µ—Ç–∞ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {e}")
            return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á–µ—Ç–∞: {e}"
    
    def get_effectiveness_by_channel(self, channels: List[str], days: int = 30) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –∂–∞–ª–æ–± –ø–æ –∫–∞–Ω–∞–ª–∞–º
        
        Args:
            channels: –°–ø–∏—Å–æ–∫ –∫–∞–Ω–∞–ª–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            days: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            Dict[str, Any]: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
        """
        try:
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –ë–î
            conn = db.pool.get_connection()
            if not conn:
                return {"error": "database_connection_error"}
                
            cursor = conn.cursor()
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–µ—Ä–∏–æ–¥
            end_date = datetime.now()
            start_date = end_date - timedelta(days=days)
            start_date_str = start_date.strftime("%Y-%m-%d %H:%M:%S")
            
            # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –∫–∞–Ω–∞–ª–∞–º
            results = {}
            
            for channel in channels:
                # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∂–∞–ª–æ–± –Ω–∞ –∫–∞–Ω–∞–ª
                cursor.execute(
                    """
                    SELECT COUNT(*) as count FROM operations
                    WHERE operation_type = 'report' AND target LIKE ?
                    AND created_at >= ?
                    """,
                    (f"%{channel}%", start_date_str)
                )
                
                total_reports = cursor.fetchone()['count']
                
                # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∂–∞–ª–æ–± –Ω–∞ –∫–∞–Ω–∞–ª
                cursor.execute(
                    """
                    SELECT result FROM operations
                    WHERE operation_type = 'report_result' AND target LIKE ?
                    AND created_at >= ?
                    """,
                    (f"%{channel}%", start_date_str)
                )
                
                result_rows = cursor.fetchall()
                
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                valid_reports = 0
                invalid_reports = 0
                flood_reports = 0
                
                for row in result_rows:
                    try:
                        result_data = json.loads(row['result'])
                        valid_reports += result_data.get('valid', 0)
                        invalid_reports += result_data.get('invalid', 0)
                        flood_reports += result_data.get('flood', 0)
                    except:
                        pass
                
                # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
                total_processed = valid_reports + invalid_reports + flood_reports
                effectiveness = (valid_reports / total_processed * 100) if total_processed > 0 else 0
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                results[channel] = {
                    "total_reports": total_reports,
                    "valid_reports": valid_reports,
                    "invalid_reports": invalid_reports,
                    "flood_reports": flood_reports,
                    "effectiveness": round(effectiveness, 2)
                }
            
            db.pool.release_connection(conn)
            
            return {
                "channels": results,
                "period_days": days
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –ø–æ –∫–∞–Ω–∞–ª–∞–º: {e}")
            return {"error": str(e)}
    
    def get_subscription_usage_stats(self, user_id: int) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–æ–¥–ø–∏—Å–∫–∏
        
        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            
        Returns:
            Dict[str, Any]: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–æ–¥–ø–∏—Å–∫–∏
        """
        try:
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ –ø–æ–¥–ø–∏—Å–∫–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            subscription = db.get_user_subscription(user_id)
            
            if not subscription:
                return {"active": False}
                
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–æ–¥–ø–∏—Å–∫–∏
            is_active = subscription.get("is_active", False)
            
            if not is_active:
                return {"active": False}
                
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ –ø–ª–∞–Ω–µ
            plan_id = subscription.get("subscription_plan", "basic")
            plan_data = config.SUBSCRIPTION_PLANS.get(plan_id, {})
            
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –¥–Ω–∏
            expires_at = subscription.get("expires_at")
            
            if not expires_at:
                return {"active": False}
                
            expires_date = datetime.strptime(expires_at, "%Y-%m-%d %H:%M:%S")
            starts_at = subscription.get("starts_at")
            start_date = datetime.strptime(starts_at, "%Y-%m-%d %H:%M:%S") if starts_at else datetime.now()
            
            current_date = datetime.now()
            
            if expires_date < current_date:
                return {"active": False}
                
            total_days = (expires_date - start_date).days
            days_left = (expires_date - current_date).days
            days_used = total_days - days_left
            
            # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–π
            conn = db.pool.get_connection()
            if not conn:
                return {
                    "active": True,
                    "plan": plan_id,
                    "plan_name": plan_data.get("name", "–ë–∞–∑–æ–≤—ã–π"),
                    "days_total": total_days,
                    "days_left": days_left,
                    "days_used": days_used,
                    "expires_at": expires_at,
                    "auto_renew": subscription.get("auto_renew", False)
                }
                
            cursor = conn.cursor()
            
            # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö –∂–∞–ª–æ–± —Å –º–æ–º–µ–Ω—Ç–∞ –Ω–∞—á–∞–ª–∞ –ø–æ–¥–ø–∏—Å–∫–∏
            cursor.execute(
                """
                SELECT COUNT(*) as count FROM operations
                WHERE user_id = ? AND operation_type = 'report'
                AND created_at >= ?
                """,
                (user_id, starts_at or "2000-01-01 00:00:00")
            )
            
            reports_count = cursor.fetchone()['count']
            
            # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∑–∞–¥–∞—á
            cursor.execute(
                """
                SELECT COUNT(*) as count FROM scheduled_tasks
                WHERE user_id = ? AND status != 'cancelled'
                AND created_at >= ?
                """,
                (user_id, starts_at or "2000-01-01 00:00:00")
            )
            
            tasks_count = cursor.fetchone()['count'] if 'scheduled_tasks' in [t[0] for t in cursor.execute("SELECT name FROM sqlite_master WHERE type='table'").fetchall()] else 0
            
            db.pool.release_connection(conn)
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            return {
                "active": True,
                "plan": plan_id,
                "plan_name": plan_data.get("name", "–ë–∞–∑–æ–≤—ã–π"),
                "days_total": total_days,
                "days_left": days_left,
                "days_used": days_used,
                "expires_at": expires_at,
                "auto_renew": subscription.get("auto_renew", False),
                "reports_count": reports_count,
                "tasks_count": tasks_count,
                "features": plan_data.get("features", []),
                "max_sessions": plan_data.get("max_sessions_per_request", 50),
                "cooldown_minutes": plan_data.get("cooldown_minutes", 5)
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–æ–¥–ø–∏—Å–∫–∏ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {e}")
            return {"active": False, "error": str(e)}

# –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä –¥–ª—è —É–¥–æ–±–Ω–æ–≥–æ –∏–º–ø–æ—Ä—Ç–∞
analytics_manager = AnalyticsManager() 